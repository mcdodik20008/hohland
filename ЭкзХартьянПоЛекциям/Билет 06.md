## 1. Случайные леса (Random Forest)

### Область применения
- Классификация и регрессия.
- Применяется в задачах, требующих устойчивости к шуму, высокому числу признаков и объяснению важности фичей (кредитный скоринг, медицина, промышленные задачи).

### Описание метода

#### Решение задачи классификации
- Строится ансамбль деревьев решений, каждое обучается на случайной подвыборке данных.
- Предсказание по классу — голосование всех деревьев (majority vote).

#### Решение задачи регрессии
- Предсказание — усреднение предсказаний всех деревьев.

#### Bootstrapping, Bagging
- **Bootstrapping:** для каждого дерева выбирается случайная подвыборка обучающих данных (с возвращением).
- **Bagging (Bootstrap Aggregating):** каждое дерево обучается независимо, результат — агрегируется (снижается дисперсия, уменьшается переобучение).

### Гиперпараметры
- **n_estimators** — число деревьев в лесу.
- **max_depth** — максимальная глубина дерева.
- **max_features** — число признаков, случайно выбираемых на каждом разбиении.
- **min_samples_split**, **min_samples_leaf** — минимальное количество объектов для разделения/в листе.
- **criterion** — функция оценки разбиения (gini, entropy, mse).

---

## 2. Сравните и сопоставьте методы деревья решений и случайных лесов

(см. таблицу из билета №5 — ключевая идея: Random Forest — это ансамбль деревьев, работающий над случайными подвыборками и признаками, более устойчив к переобучению, но менее интерпретируем)

---

### Объясните разницу между задачами классификации и регрессии в машинном обучении

- **Классификация:** выход — метка класса (категория), задача разделения объектов по группам.
- **Регрессия:** выход — непрерывное числовое значение (предсказание количества, цены и т.д.).

