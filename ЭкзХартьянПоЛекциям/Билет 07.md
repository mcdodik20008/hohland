## 1. Бустинг — AdaBoost

### Область применения
- Классификация и регрессия, особенно задачи с большим количеством "шумных" данных и сложными границами.
- Используется, когда одиночные слабые модели (например, простые деревья) плохо справляются с задачей.

### Описание метода: Формула бустинга, AdaBoost, Процесс AdaBoost

#### Формула бустинга
- Итоговая модель — взвешенная сумма слабых моделей:
  $$
  F(x) = \sum_{m=1}^{M} \alpha_m h_m(x)
  $$
  где \( h_m(x) \) — слабый алгоритм (например, дерево), \( \alpha_m \) — вес модели, \( M \) — количество итераций.

#### Процесс AdaBoost
1. Всем объектам обучающей выборки присваиваются одинаковые веса.
2. На каждом шаге строится новое слабое дерево, уделяя больше внимания ошибочно классифицированным объектам (их веса увеличиваются).
3. Каждая новая модель получает свой вес в итоговой композиции, в зависимости от точности.
4. Итоговое решение — взвешенное голосование всех моделей.

### Гиперпараметры
- **n_estimators** — число слабых моделей (итераций).
- **learning_rate** — скорость обучения (уменьшает вклад каждой модели).
- **base_estimator** — тип слабой модели (обычно DecisionTree с max_depth=1).

### Сравните и сопоставьте методы градиентный бустинг и AdaBoost

|                | **AdaBoost**                         | **Градиентный бустинг**                |
| -------------- | ------------------------------------ | -------------------------------------- |
| Идея           | Повышает веса ошибочных объектов     | Моделирует антиградиент функции потерь |
| Базовые модели | Обычно простые (stump)               | Любые слабые алгоритмы                 |
| Тип ошибок     | Работает с экспоненциальной функцией | Любая дифференцируемая функция потерь  |
| Скорость       | Быстрее, проще в реализации          | Гибче, точнее, но сложнее и медленнее  |
| Настройка      | Меньше параметров                    | Много параметров                       |

---

## 2. Объясните концепцию обнаружения аномалий в данных и работу с ними

### Концепция
- **Аномалии** — объекты, не соответствующие общей закономерности данных (выбросы, ошибки, мошенничество).
- Методы: статистические тесты, методы кластеризации, расстояний, алгоритмы типа Isolation Forest, LOF.

### Работа с аномалиями
- Анализ: выявление причин (ошибка, редкое событие, мошенничество).
- Корректировка/удаление (если ошибка).
- Отдельная обработка (например, для поиска мошенников).

---

### Как бы вы поступили с отсутствующими данными в наборе данных?

- Удаление строк/столбцов с пропусками (если их мало).
- Заполнение (импутация): среднее, медиана, наиболее частое значение.
- Моделирование пропусков: предсказание на основе других признаков, мультиимпутация.
- Использование алгоритмов, устойчивых к пропускам (например, деревья решений).
