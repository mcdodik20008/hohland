## 1. Бустинг — градиентный бустинг (Gradient Boosting)

### Область применения
- Задачи классификации и регрессии на табличных данных, где требуется высокая точность и способность справляться с различными типами признаков.
- Широко применяется в соревнованиях по машинному обучению (Kaggle, Data Science Cup и др.).

### Описание метода: процесс градиентного бустинга

- Итоговая модель строится как сумма слабых моделей (обычно решающих деревьев).
- На каждом шаге новое дерево учится аппроксимировать антиградиент функции потерь по текущим ошибкам ансамбля.
- Обновление ансамбля:
  $$
  F_{m}(x) = F_{m-1}(x) + \alpha \cdot h_m(x)
  $$
  где \( F_{m-1}(x) \) — предсказание текущего ансамбля, \( h_m(x) \) — новое дерево, \( \alpha \) — learning rate.

### Гиперпараметры
- **n_estimators** — количество деревьев в ансамбле.
- **learning_rate** — скорость обучения (вес новой модели).
- **max_depth** — глубина дерева.
- **subsample, colsample_bytree** — доля объектов/признаков для каждого дерева.

### Сравните и сопоставьте методы градиентный бустинг и AdaBoost

(см. таблицу в билете №7:  
**Градиентный бустинг** — строит модели по антиградиенту ошибки, гибче, поддерживает любые функции потерь, настраивается детальнее, требует больше вычислений.  
**AdaBoost** — простейший бустинг, использует экспоненциальную функцию потерь, проще по гиперпараметрам.)

---

## 2. Как бы вы поступили с отсутствующими данными в наборе данных?

- Анализ пропусков (тип, причина).
- Удаление строк/столбцов (если доля пропусков незначительна).
- Заполнение (импутация): среднее, медиана, мода, специальные методы (KNN, MICE).
- Использование моделей устойчивых к пропускам.

---

### Какими способами можно уменьшить размерность набора данных?

- **Методы отбора признаков (Feature Selection):**
  - Удаление малоинформативных признаков.
  - Автоматический отбор по важности признаков (feature importance).
- **Методы понижения размерности (Feature Extraction):**
  - **PCA** (метод главных компонент).
  - **t-SNE**, **UMAP** — для визуализации и анализа кластеров.
  - Автоэнкодеры (нейронные сети).
